# Prince Chat

Welcome to Prince Chat, a sleek and modern chat application that allows you to interact with your own locally hosted Ollama models. Built with Next.js and styled with ShadCN UI and Tailwind CSS, Prince Chat provides a beautiful and responsive interface for all your generative AI conversations.

## Features

- **Connect to Local Ollama Models:** Seamlessly connect to your Ollama instance running on your local machine.
- **Dynamic Model Selection:** Automatically fetches a list of your available Ollama models and lets you switch between them on the fly with a convenient dropdown menu.
- **Real-time Streaming:** Watch the AI's response generate in real-time for a natural and engaging chat experience.
- **Stop Generation:** Don't like the response? You can stop the generation at any time with a single click.
- **Copy Responses:** Easily copy the complete response from the AI to your clipboard.
- **Light & Dark Mode:** Toggle between light and dark themes to suit your preference.
- **Responsive Design:** Enjoy a consistent experience across all your devices.

## Getting Started

1.  **Run Ollama:** Make sure your local Ollama instance is running.
2.  **Start the app:**
    ```bash
    npm run dev
    ```
3.  Open your browser to `http://localhost:9002` and start chatting!

![image](https://github.com/user-attachments/assets/5cb7e689-3544-4a49-b73f-c949d813bb56)

